{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "78yY-7zew0IU"
      },
      "source": [
        "# import all the required libraries.\n",
        "# These includes libraries for preprocessing, and training the models\n",
        "import re\n",
        "import nltk\n",
        "import keras\n",
        "import emoji\n",
        "import torch\n",
        "import wordsegment\n",
        "import numpy as np\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from keras.layers import Dense\n",
        "from sklearn import naive_bayes\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import f1_score\n",
        "from wordsegment import load, segment\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import DistilBertTokenizer, DistilBertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtTO7SnIxmdk",
        "outputId": "dc070716-e2ae-4fcb-9087-08e3f2113675"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVaTIpRzxT-R"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/OLIDv1.0/olid-training-v1.0.tsv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azvSqQVz21uY"
      },
      "source": [
        "data_test_a = pd.read_csv('drive/My Drive/OLIDv1.0/testset-levela.tsv', sep='\\t')\n",
        "data_test_b = pd.read_csv('drive/My Drive/OLIDv1.0/testset-levelb.tsv', sep='\\t')\n",
        "data_test_c = pd.read_csv('drive/My Drive/OLIDv1.0/testset-levelc.tsv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwsOO5fA24s9"
      },
      "source": [
        "label_test_a = pd.read_csv('drive/My Drive/OLIDv1.0/labels-levela.csv', header=None)\n",
        "label_test_b = pd.read_csv('drive/My Drive/OLIDv1.0/labels-levelb.csv', header=None)\n",
        "label_test_c = pd.read_csv('drive/My Drive/OLIDv1.0/labels-levelc.csv', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OALyeI3oxUBf"
      },
      "source": [
        "# function for preprocessing the tweets\n",
        "def t_preprocess(x):\n",
        "    pred = []\n",
        "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "    stopwords.update(['url'])\n",
        "    txt = re.compile(r'[^a-zA-Z]')\n",
        "    # Removing @ user tags from data\n",
        "    usr_rmv = re.compile(\"@[A-Za-z0-9]+\")\n",
        "    # Removing # tags from data \n",
        "    hash_rmv = re.compile(\"#[A-Za-z0-9]+\") \n",
        "    # Regex pattern for whole-word numbers\n",
        "    number_pattern = re.compile(r'\\b\\d+\\b')\n",
        "    enti = []\n",
        "    # segment the words with #. For eg. #nojustice becomes no justice\n",
        "    load()\n",
        "    for i in range(0, len(x)):\n",
        "      print\n",
        "      sent_tokens = x[i].split(' ')\n",
        "      for j, t in enumerate(sent_tokens):\n",
        "          if t.find('#') == 0:\n",
        "              sent_tokens[j] = ' '.join(wordsegment.segment(t))\n",
        "      x[i] = ' '.join(sent_tokens)\n",
        "    \n",
        "    # Loop through each tweet in the data list to do the preprocessing\n",
        "    for j in range(0, len(x)):\n",
        "        lines = x[j].split(\"\\n\")\n",
        "        for i in range(0, len(lines)):\n",
        "            lines[i] = usr_rmv.sub('', lines[i])\n",
        "            # convert emojis to words\n",
        "            lines[i] = emoji.demojize(lines[i])\n",
        "            lines[i] = number_pattern.sub('', lines[i])\n",
        "            filters='!\"\\'$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "            translate_dict = dict((c, \" \") for c in filters)\n",
        "            translate_map = str.maketrans(translate_dict)\n",
        "            lines[i] = lines[i].translate(translate_map)\n",
        "            lines[i] = txt.sub(' ', lines[i])\n",
        "            lines[i] = lines[i].lower()\n",
        "            # Remove short words\n",
        "            lines[i] = ' '.join([w for w in lines[i].split() if len(w) > 2])\n",
        "            # Remove stopwords\n",
        "            lines[i] = ' '.join([w for w in lines[i].split() if w not in stopwords])\n",
        "            # Remove extra spaces, just for beauty\n",
        "            re.sub('\\s\\s+', \" \", lines[i])\n",
        "            lines[i] = \" \".join(lines[i].split())\n",
        "\n",
        "        pre = \" \".join(lines)\n",
        "        pred.append(pre)\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YTIY36tp_v_"
      },
      "source": [
        "TASK A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbSnHBL6y997"
      },
      "source": [
        "# call to the preprocessing function.\n",
        "data_pre = t_preprocess(data['tweet'].tolist())\n",
        "data_pre_test = t_preprocess(data_test_a['tweet'].tolist())\n",
        "y_true = label_test_a[1].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWPWpqUExUEY"
      },
      "source": [
        "# get the vectors for the tweets in the train and test data using count vectorizer.\n",
        "# here processed tweets are used.\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "vectorizer.fit(data_pre)\n",
        "\n",
        "train_vectors = vectorizer.transform(data_pre)\n",
        "test_vectors = vectorizer.transform(data_pre_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3FhjfsoxUHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141da7b0-471a-4c9b-a5bc-7f47415892d3"
      },
      "source": [
        "# training logistic regression model for subtask a on count vectorizer\n",
        "model = LogisticRegression()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4s7p0vdxUKe"
      },
      "source": [
        "# testing Logistic regression model on test data of subtask a on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDSSofgfxUM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a79a88-b206-4a7a-e033-5427f68381d5"
      },
      "source": [
        "# get f1-score for subtask a for logistic regression model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7110804097871795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYrZTx6C6Jun"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyz6_XSt6Tc7",
        "outputId": "7d382e1f-e593-4c29-b3c2-37d5bd564d00"
      },
      "source": [
        "# training naive bayes model for subtask a on count vectorizer\n",
        "model = naive_bayes.MultinomialNB()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mvTwfEr6JyV"
      },
      "source": [
        "# testing naive bayes model on test data of subtask a on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZWnPMpV6J1j",
        "outputId": "3c9f8290-fecc-4c4b-b13b-4186c5f71f62"
      },
      "source": [
        "# get f1-score for subtask a for naive bayes model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6869907602716496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGSKZrik6J8h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxKlkJrP6J_t",
        "outputId": "ea7f40c2-5b2a-4c74-9078-fe47b793b50d"
      },
      "source": [
        "# training Random Forest model for subtask a on count vectorizer\n",
        "model = RandomForestClassifier()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELsrudA96gts"
      },
      "source": [
        "# testing Random Forest model on test data of subtask a on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Y_uhhv6gwo",
        "outputId": "e3e29159-4689-4432-d351-6188fcc67e67"
      },
      "source": [
        "# get f1-score for subtask a for Random Forest model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7209965149443407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUzEtmYI6gzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPeWG4EF6g1-",
        "outputId": "fd881523-dc6b-4a16-de14-76bf8467e4f9"
      },
      "source": [
        "# training XGBoost model for subtask a on count vectorizer\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CK_Sv3V6g4s"
      },
      "source": [
        "# testing XGBoost model on test data of subtask a on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZAKvjr-6g7k",
        "outputId": "60d15be9-e985-49f6-dd92-8265c4eaff9a"
      },
      "source": [
        "# get f1-score for subtask a for XGBoost model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6457193500475417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH3BphJ896tP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP52geg296wl"
      },
      "source": [
        "# get the vectors for the tweets in the train and test data using tfidf vectorizer.\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "vectorizer.fit(data_pre)\n",
        "\n",
        "train_vectors = vectorizer.transform(data_pre)\n",
        "test_vectors = vectorizer.transform(data_pre_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dDhPGRX7aEw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSxwK6Hl-Oov",
        "outputId": "015047f2-0d81-42b0-ac68-acebd52cec07"
      },
      "source": [
        "# training logistic regression model for subtask a on tfidf vectorizer\n",
        "model = LogisticRegression()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4tbUTOP-Oow"
      },
      "source": [
        "# testing Logistic regression model on test data of subtask a on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9s9zAAx-Oow",
        "outputId": "c115c21c-d94f-4f37-dfec-5851b0b7e999"
      },
      "source": [
        "# get f1-score for subtask a for logistic regression model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6822019869317903"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXZOoDS_-Ooz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg5CdMnK-Ooz",
        "outputId": "e66bfb47-7dac-4cc5-b474-d3bed4999a1e"
      },
      "source": [
        "# training naive bayes model for subtask a on tfidf vectorizer\n",
        "model = naive_bayes.MultinomialNB()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRo6vI9e-Ooz"
      },
      "source": [
        "# testing naive bayes model on test data of subtask a on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpsOy3gD-Ooz",
        "outputId": "43c5c125-7418-4b54-9702-4697fd1b1722"
      },
      "source": [
        "# get f1-score for subtask a for naive bayes model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.500204190619797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW_oWaOg-Ooz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k78FQT72-Ooz",
        "outputId": "85da84be-6abe-4f85-a834-c1b2c605f3e5"
      },
      "source": [
        "# training Random Forest model for subtask a on tfidf vectorizer\n",
        "model = RandomForestClassifier()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "363tG2Xm-Ooz"
      },
      "source": [
        "# testing Random Forest model on test data of subtask a on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7BEUlPn-Ooz",
        "outputId": "9ad566cf-a0e7-4665-922d-9a42670fbb02"
      },
      "source": [
        "# get f1-score for subtask a for Random Forest model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.718479924886163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgRQcWKN-Ooz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa94DagO-Oo0",
        "outputId": "276448fb-907a-4a31-88c9-5dc40de6b34f"
      },
      "source": [
        "# training XGBoost model for subtask a on tfidf vectorizer\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(train_vectors, data['subtask_a'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxwpSjIQ-Oo0"
      },
      "source": [
        "# testing XGBoost model on test data of subtask a on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ7XuwFE-Oo0",
        "outputId": "a275e965-94ee-42cd-99fe-2ff1fe5db32e"
      },
      "source": [
        "# get f1-score for subtask a for XGBoost model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6418892889669746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrB9x01j-Pcu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxTxv00l7aH9"
      },
      "source": [
        "# get word embeddings of the tweets using distil bert for training set\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "feat_train = []\n",
        "for i in tqdm(range(len(data_pre))):\n",
        "    inputs = tokenizer(data_pre[i], return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    feat.append(outputs)\n",
        "\n",
        "np.save('distilbert_features.npy', feat_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSP_tLwO7aK9"
      },
      "source": [
        "# get word embeddings of the tweets using distil bert for test set\n",
        "feat_test = []\n",
        "for i in tqdm(range(len(data_pre_test))):\n",
        "    inputs = tokenizer(data_pre_test[i], return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    feat.append(outputs)\n",
        "\n",
        "np.save('distilbert_testa_features.npy', feat_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpy4U2P67aNu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhew4DmM7aQg"
      },
      "source": [
        "feat = np.load(\"/content/drive/MyDrive/OLIDv1.0/distilbert_features.npy\",allow_pickle=True)\n",
        "feat_test = np.load(\"/content/drive/MyDrive/OLIDv1.0/distilbert_testa_features.npy\",allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4EGjXdQUSC8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiVMBR4e7aUT"
      },
      "source": [
        "train_vectors = []\n",
        "for i in range(len(feat)):\n",
        "  train_vectors.append(feat[i][0][0][0].detach().numpy())\n",
        "\n",
        "test_vectors = []\n",
        "for i in range(len(feat_test)):\n",
        "  test_vectors.append(feat_test[i][0][0][0].detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI3KKJqTBtHu"
      },
      "source": [
        "y = pd.factorize(data['subtask_a'])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjB27acuB9BL"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(2480, input_dim=768, activation='relu'))\n",
        "model.add(Dense(1260, activation='relu'))\n",
        "model.add(Dense(640, activation='relu'))\n",
        "model.add(Dense(320, activation='relu'))\n",
        "model.add(Dense(160, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WflazKuFC0H"
      },
      "source": [
        "# compile keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1XBbwZmZG-Y",
        "outputId": "2dbe6eb7-4528-4c60-cc0d-86c77ab76611"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_58 (Dense)             (None, 2480)              1907120   \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1260)              3126060   \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 640)               807040    \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 320)               205120    \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 160)               51360     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 64)                10304     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 6,109,757\n",
            "Trainable params: 6,109,757\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYRPc6v4FR5U"
      },
      "source": [
        "# reshape the training embeddings obtained\n",
        "a = np.array(train_vectors)\n",
        "train_vec = np.vstack(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klm_MtuJGfXh",
        "outputId": "b7d7dd3f-0fe4-4dfa-e0c1-2208dafefa52"
      },
      "source": [
        "# train the model\n",
        "model.fit(train_vec, y, epochs=50, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "207/207 [==============================] - 16s 72ms/step - loss: 0.4843 - accuracy: 0.7615\n",
            "Epoch 2/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4786 - accuracy: 0.7681\n",
            "Epoch 3/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4760 - accuracy: 0.7678\n",
            "Epoch 4/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.4743 - accuracy: 0.7681\n",
            "Epoch 5/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4706 - accuracy: 0.7729\n",
            "Epoch 6/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4665 - accuracy: 0.7736\n",
            "Epoch 7/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.4646 - accuracy: 0.7774\n",
            "Epoch 8/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4618 - accuracy: 0.7780\n",
            "Epoch 9/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4594 - accuracy: 0.7823\n",
            "Epoch 10/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4535 - accuracy: 0.7857\n",
            "Epoch 11/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4493 - accuracy: 0.7854\n",
            "Epoch 12/50\n",
            "207/207 [==============================] - 16s 77ms/step - loss: 0.4468 - accuracy: 0.7872\n",
            "Epoch 13/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4419 - accuracy: 0.7911\n",
            "Epoch 14/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4360 - accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4248 - accuracy: 0.7990\n",
            "Epoch 16/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4203 - accuracy: 0.8025\n",
            "Epoch 17/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4100 - accuracy: 0.8087\n",
            "Epoch 18/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.4028 - accuracy: 0.8115\n",
            "Epoch 19/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.3912 - accuracy: 0.8230\n",
            "Epoch 20/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.3801 - accuracy: 0.8255\n",
            "Epoch 21/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.3681 - accuracy: 0.8321\n",
            "Epoch 22/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.3556 - accuracy: 0.8378\n",
            "Epoch 23/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.3418 - accuracy: 0.8450\n",
            "Epoch 24/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.3265 - accuracy: 0.8554\n",
            "Epoch 25/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.3148 - accuracy: 0.8608\n",
            "Epoch 26/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.3079 - accuracy: 0.8614\n",
            "Epoch 27/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.2861 - accuracy: 0.8751\n",
            "Epoch 28/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.2711 - accuracy: 0.8816\n",
            "Epoch 29/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.2602 - accuracy: 0.8873\n",
            "Epoch 30/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.2491 - accuracy: 0.8946\n",
            "Epoch 31/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.2285 - accuracy: 0.9035\n",
            "Epoch 32/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.2109 - accuracy: 0.9081\n",
            "Epoch 33/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.1981 - accuracy: 0.9150\n",
            "Epoch 34/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.1993 - accuracy: 0.9165\n",
            "Epoch 35/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.1699 - accuracy: 0.9310\n",
            "Epoch 36/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.1597 - accuracy: 0.9341\n",
            "Epoch 37/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.1429 - accuracy: 0.9432\n",
            "Epoch 38/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.1344 - accuracy: 0.9443\n",
            "Epoch 39/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.1286 - accuracy: 0.9483\n",
            "Epoch 40/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.1187 - accuracy: 0.9529\n",
            "Epoch 41/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.1002 - accuracy: 0.9609\n",
            "Epoch 42/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.1006 - accuracy: 0.9624\n",
            "Epoch 43/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.0922 - accuracy: 0.9661\n",
            "Epoch 44/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.0849 - accuracy: 0.9676\n",
            "Epoch 45/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.1026 - accuracy: 0.9627\n",
            "Epoch 46/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.0823 - accuracy: 0.9687\n",
            "Epoch 47/50\n",
            "207/207 [==============================] - 15s 73ms/step - loss: 0.0749 - accuracy: 0.9714\n",
            "Epoch 48/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.0890 - accuracy: 0.9687\n",
            "Epoch 49/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.0703 - accuracy: 0.9735\n",
            "Epoch 50/50\n",
            "207/207 [==============================] - 15s 72ms/step - loss: 0.0611 - accuracy: 0.9782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d0fb26d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KWRMZZeYGwQ"
      },
      "source": [
        "# reshape test embeddings\n",
        "a = np.array(test_vectors)\n",
        "test_vec = np.vstack(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ3r9_lXZBlZ"
      },
      "source": [
        "# get test labels in binary form\n",
        "y_test = pd.factorize(y_true)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UB16uQJU-gR"
      },
      "source": [
        "# get predictions for test set of subtask a\n",
        "y_pred = model.predict(test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J676Nq63Uob-"
      },
      "source": [
        "res=[]\n",
        "for prediction in y_pred:\n",
        "    if prediction[0]<0.5:\n",
        "        res.append(0)\n",
        "    else:\n",
        "        res.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPmIjA8SV_Bh",
        "outputId": "7b30f59a-912d-482c-bf85-1e18c437da1e"
      },
      "source": [
        "# calculate f1 score for subtask a\n",
        "f1_score(y_test, res, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7116849868947721"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d-bdrusWCC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1LyTP-wUofL"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(2480, input_dim=768, activation='relu'))\n",
        "model.add(Dense(1260, activation='relu'))\n",
        "model.add(Dense(640, activation='relu'))\n",
        "model.add(Dense(160, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mn5Wgv0Uoh6"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TK-FyGvZOxF",
        "outputId": "44636e4d-eb23-4174-cfa4-ad7b5be35b25"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_68 (Dense)             (None, 2480)              1907120   \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 1260)              3126060   \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 640)               807040    \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 160)               102560    \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 64)                10304     \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,955,709\n",
            "Trainable params: 5,955,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grMjN4LLUrVF",
        "outputId": "a409b3f9-086f-4bf6-cd5b-201a50f36cca"
      },
      "source": [
        "# train the model\n",
        "model.fit(train_vec, y, epochs=50, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.6167 - accuracy: 0.6677\n",
            "Epoch 2/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.5753 - accuracy: 0.6945\n",
            "Epoch 3/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.5541 - accuracy: 0.7179\n",
            "Epoch 4/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5362 - accuracy: 0.7329\n",
            "Epoch 5/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5295 - accuracy: 0.7328\n",
            "Epoch 6/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5195 - accuracy: 0.7400\n",
            "Epoch 7/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5110 - accuracy: 0.7446\n",
            "Epoch 8/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5125 - accuracy: 0.7424\n",
            "Epoch 9/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5094 - accuracy: 0.7437\n",
            "Epoch 10/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5048 - accuracy: 0.7455\n",
            "Epoch 11/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.5023 - accuracy: 0.7498\n",
            "Epoch 12/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4995 - accuracy: 0.7529\n",
            "Epoch 13/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4983 - accuracy: 0.7539\n",
            "Epoch 14/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4985 - accuracy: 0.7534\n",
            "Epoch 15/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4917 - accuracy: 0.7579\n",
            "Epoch 16/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4912 - accuracy: 0.7584\n",
            "Epoch 17/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4890 - accuracy: 0.7586\n",
            "Epoch 18/50\n",
            "207/207 [==============================] - 13s 63ms/step - loss: 0.4861 - accuracy: 0.7601\n",
            "Epoch 19/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4895 - accuracy: 0.7586\n",
            "Epoch 20/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4858 - accuracy: 0.7631\n",
            "Epoch 21/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4866 - accuracy: 0.7632\n",
            "Epoch 22/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4841 - accuracy: 0.7635\n",
            "Epoch 23/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4838 - accuracy: 0.7634\n",
            "Epoch 24/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4800 - accuracy: 0.7661\n",
            "Epoch 25/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4753 - accuracy: 0.7693\n",
            "Epoch 26/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4813 - accuracy: 0.7660\n",
            "Epoch 27/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4762 - accuracy: 0.7706\n",
            "Epoch 28/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4765 - accuracy: 0.7692\n",
            "Epoch 29/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4745 - accuracy: 0.7699\n",
            "Epoch 30/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4678 - accuracy: 0.7781\n",
            "Epoch 31/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4675 - accuracy: 0.7731\n",
            "Epoch 32/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4664 - accuracy: 0.7779\n",
            "Epoch 33/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4683 - accuracy: 0.7757\n",
            "Epoch 34/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4713 - accuracy: 0.7787\n",
            "Epoch 35/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4655 - accuracy: 0.7767\n",
            "Epoch 36/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4606 - accuracy: 0.7799\n",
            "Epoch 37/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4590 - accuracy: 0.7827\n",
            "Epoch 38/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4598 - accuracy: 0.7797\n",
            "Epoch 39/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4569 - accuracy: 0.7849\n",
            "Epoch 40/50\n",
            "207/207 [==============================] - 12s 60ms/step - loss: 0.4539 - accuracy: 0.7872\n",
            "Epoch 41/50\n",
            "207/207 [==============================] - 12s 60ms/step - loss: 0.4531 - accuracy: 0.7857\n",
            "Epoch 42/50\n",
            "207/207 [==============================] - 12s 60ms/step - loss: 0.4505 - accuracy: 0.7850\n",
            "Epoch 43/50\n",
            "207/207 [==============================] - 12s 60ms/step - loss: 0.4488 - accuracy: 0.7847\n",
            "Epoch 44/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4482 - accuracy: 0.7905\n",
            "Epoch 45/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4447 - accuracy: 0.7900\n",
            "Epoch 46/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4454 - accuracy: 0.7860\n",
            "Epoch 47/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4416 - accuracy: 0.7917\n",
            "Epoch 48/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4369 - accuracy: 0.7958\n",
            "Epoch 49/50\n",
            "207/207 [==============================] - 13s 61ms/step - loss: 0.4337 - accuracy: 0.7992\n",
            "Epoch 50/50\n",
            "207/207 [==============================] - 13s 62ms/step - loss: 0.4364 - accuracy: 0.7934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d0b3b9e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izhiHwF8UrXw"
      },
      "source": [
        "# get test predictions for subtask a\n",
        "y_pred = model.predict(test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndgc4XQSUram"
      },
      "source": [
        "res=[]\n",
        "for prediction in y_pred:\n",
        "    if prediction[0]<0.5:\n",
        "        res.append(0)\n",
        "    else:\n",
        "        res.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVLwHgfLUrcv",
        "outputId": "82729db9-f926-4f6f-df3d-87cd046a9237"
      },
      "source": [
        "# get f1 score\n",
        "f1_score(y_test, res, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6957808078209416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4tJTThQWnFB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQFGCZK_nMVz"
      },
      "source": [
        "TASK B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqyzbVgZWnLW"
      },
      "source": [
        "# load data for training\n",
        "data = pd.read_csv('/content/drive/MyDrive/OLIDv1.0/olid-training-v1.0.tsv', sep='\\t')\n",
        "data = data[data['subtask_b'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQQpJA87Wnkd"
      },
      "source": [
        "# call to the preprocessing function.\n",
        "data_pre = t_preprocess(data['tweet'].tolist())\n",
        "data_pre_test = t_preprocess(data_test_b['tweet'].tolist())\n",
        "y_true = label_test_b[1].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pV-GnJSWnkd"
      },
      "source": [
        "# get the vectors for the tweets in the train and test data using count vectorizer.\n",
        "# here processed tweets are used.\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "vectorizer.fit(data_pre)\n",
        "\n",
        "train_vectors = vectorizer.transform(data_pre)\n",
        "test_vectors = vectorizer.transform(data_pre_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_ybV7zaWnkd",
        "outputId": "08366bf9-9a38-4bf5-e6f0-ccdb0981fb9b"
      },
      "source": [
        "# training logistic regression model for subtask b on count vectorizer\n",
        "model = LogisticRegression()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jxpYZVIWnke"
      },
      "source": [
        "# testing Logistic regression model on test data of subtask b on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBvI6AwlWnke",
        "outputId": "3767caa1-4ae4-4798-9bed-c921cf5538cf"
      },
      "source": [
        "# get f1-score for subtask b for logistic regression model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4678492239467849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRtpI3W9Wnke"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t350zQZRWnke",
        "outputId": "c75e7517-9466-4c87-984d-ded9ba28af10"
      },
      "source": [
        "# training naive bayes model for subtask b on count vectorizer\n",
        "model = naive_bayes.MultinomialNB()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJNYO15AWnke"
      },
      "source": [
        "# testing naive bayes model on test data of subtask b on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJdcCVdcWnke",
        "outputId": "ba7f372a-0a47-4541-fa6e-4138485618bc"
      },
      "source": [
        "# get f1-score for subtask b for naive bayes model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4690265486725663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIKzlXvtWnkf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsyH04WrWnkf",
        "outputId": "b61e9a25-d120-4f96-8a0e-aca8b61e42e2"
      },
      "source": [
        "# training Random Forest model for subtask b on count vectorizer\n",
        "model = RandomForestClassifier()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y35DgaxXWnkf"
      },
      "source": [
        "# testing Random Forest model on test data of subtask b on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvI-HUMAWnkf",
        "outputId": "2898b213-ec85-40e3-9a81-2552d786c1d8"
      },
      "source": [
        "# get f1-score for subtask b for Random Forest model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5607077486272117"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af7HViHbWnkf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flcbM7vLWnkf",
        "outputId": "a82f5f5c-ac1d-425c-f250-5eabed5ae1ff"
      },
      "source": [
        "# training XGBoost model for subtask b on count vectorizer\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F22eqO4_Wnkg"
      },
      "source": [
        "# testing XGBoost model on test data of subtask b on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlVi4V3SWnkg",
        "outputId": "ac242b6e-f080-45ea-a213-721e39fe2437"
      },
      "source": [
        "# get f1-score for subtask b for XGBoost model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47019867549668876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH8ARCidWnkg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBFxsaqkWnkg"
      },
      "source": [
        "# get the vectors for the tweets in the train and test data using tfidf vectorizer.\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "vectorizer.fit(data_pre)\n",
        "\n",
        "train_vectors = vectorizer.transform(data_pre)\n",
        "test_vectors = vectorizer.transform(data_pre_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjfRggiyWnkg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6hZuPLvWnkg",
        "outputId": "53908f99-a466-4c6b-b549-7097727b8bfb"
      },
      "source": [
        "# training logistic regression model for subtask b on tfidf vectorizer\n",
        "model = LogisticRegression()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSythwNyWnkg"
      },
      "source": [
        "# testing Logistic regression model on test data of subtask b on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHQyHqvmWnkg",
        "outputId": "73de1161-4fad-4a2a-8ec0-332c63cd78b6"
      },
      "source": [
        "# get f1-score for subtask b for logistic regression model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4690265486725663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI5hKnOaWnkg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DmL4ZqPWnkg",
        "outputId": "d201f988-7259-440d-f04c-32fb5e656153"
      },
      "source": [
        "# training naive bayes model for subtask b on tfidf vectorizer\n",
        "model = naive_bayes.MultinomialNB()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRGecbPYWnkg"
      },
      "source": [
        "# testing naive bayes model on test data of subtask b on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmMe57lxWnkg",
        "outputId": "720d5de5-54e4-4df0-9a48-8240818059e5"
      },
      "source": [
        "# get f1-score for subtask b for naive bayes model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47019867549668876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR3TQAorWnkh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSgl4L0HWnkh",
        "outputId": "03e2fbd8-0b73-4d26-f6fd-406c8fb69c8e"
      },
      "source": [
        "# training Random Forest model for subtask b on tfidf vectorizer\n",
        "model = RandomForestClassifier()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeJl7pPsWnkh"
      },
      "source": [
        "# testing Random Forest model on test data of subtask b on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhA-LghKWnkh",
        "outputId": "e16172d1-b8e7-4237-d1f7-e166ab461339"
      },
      "source": [
        "# get f1-score for subtask b for Random Forest model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4678492239467849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ99eTb4Wnkh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlHAb1N4Wnkh",
        "outputId": "6c6b47da-2710-465a-90f4-6f3787262590"
      },
      "source": [
        "# training XGBoost model for subtask b on tfidf vectorizer\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(train_vectors, data['subtask_b'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ1UC7c5Wnkh"
      },
      "source": [
        "# testing XGBoost model on test data of subtask b on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLerwOz6Wnkh",
        "outputId": "23b9aaf7-2037-4778-e10b-43615ffefa2a"
      },
      "source": [
        "# get f1-score for subtask b for XGBoost model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4690265486725663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X285KFeWnkh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6VLfrW8Wnkh"
      },
      "source": [
        "# get word embeddings of the tweets using distil bert for training set\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "feat_train = []\n",
        "for i in tqdm(range(len(data_pre))):\n",
        "    inputs = tokenizer(data_pre[i], return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    feat.append(outputs)\n",
        "\n",
        "np.save('distilbert_features.npy', feat_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anKzC63KWnkh"
      },
      "source": [
        "# get word embeddings of the tweets using distil bert for test set\n",
        "feat_test = []\n",
        "for i in tqdm(range(len(data_pre_test))):\n",
        "    inputs = tokenizer(data_pre_test[i], return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    feat.append(outputs)\n",
        "\n",
        "np.save('distilbert_testb_features.npy', feat_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiirD3sIWnki"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OZzkuv7Wnki"
      },
      "source": [
        "feat = np.load(\"/content/drive/MyDrive/OLIDv1.0/distilbert_features.npy\",allow_pickle=True)\n",
        "feat_test = np.load(\"/content/drive/MyDrive/OLIDv1.0/distilbert_testb_features.npy\",allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJNeNQJMdAFQ"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/OLIDv1.0/olid-training-v1.0.tsv', sep='\\t')\n",
        "data['bert'] = feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6p1qMvTWnki"
      },
      "source": [
        "# remove tweets with Null label\n",
        "data = data[data['subtask_b'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkaMcC04dWB-"
      },
      "source": [
        "feat = data['bert'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoEA2mtNWnki"
      },
      "source": [
        "train_vectors = []\n",
        "for i in range(len(feat)):\n",
        "  train_vectors.append(feat[i][0][0][0].detach().numpy())\n",
        "\n",
        "test_vectors = []\n",
        "for i in range(len(feat_test)):\n",
        "  test_vectors.append(feat_test[i][0][0][0].detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9nW3VaZWnki"
      },
      "source": [
        "y = pd.factorize(data['subtask_b'])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS_5KRgxWnki"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(2480, input_dim=768, activation='relu'))\n",
        "model.add(Dense(1260, activation='relu'))\n",
        "model.add(Dense(640, activation='relu'))\n",
        "model.add(Dense(320, activation='relu'))\n",
        "model.add(Dense(160, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfiUjDodWnki"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5RrnH8DWnki"
      },
      "source": [
        "# reshape the vector\n",
        "a = np.array(train_vectors)\n",
        "train_vec = np.vstack(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYpV2q2EWnki",
        "outputId": "9f33db9b-b44f-4b85-d5de-e28ff9d55334"
      },
      "source": [
        "# train the model\n",
        "model.fit(train_vec, y, epochs=25, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.3335 - accuracy: 0.8809\n",
            "Epoch 2/25\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.3350 - accuracy: 0.8809\n",
            "Epoch 3/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3253 - accuracy: 0.8809\n",
            "Epoch 4/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3355 - accuracy: 0.8809\n",
            "Epoch 5/25\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.3243 - accuracy: 0.8809\n",
            "Epoch 6/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3219 - accuracy: 0.8809\n",
            "Epoch 7/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3136 - accuracy: 0.8809\n",
            "Epoch 8/25\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.3105 - accuracy: 0.8809\n",
            "Epoch 9/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.3110 - accuracy: 0.8809\n",
            "Epoch 10/25\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.3053 - accuracy: 0.8809\n",
            "Epoch 11/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2985 - accuracy: 0.8809\n",
            "Epoch 12/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2924 - accuracy: 0.8809\n",
            "Epoch 13/25\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.2827 - accuracy: 0.8809\n",
            "Epoch 14/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2751 - accuracy: 0.8809\n",
            "Epoch 15/25\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.2714 - accuracy: 0.8809\n",
            "Epoch 16/25\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.2613 - accuracy: 0.8809\n",
            "Epoch 17/25\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.2493 - accuracy: 0.8950\n",
            "Epoch 18/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2552 - accuracy: 0.8993\n",
            "Epoch 19/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2314 - accuracy: 0.9020\n",
            "Epoch 20/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2401 - accuracy: 0.9018\n",
            "Epoch 21/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2179 - accuracy: 0.9050\n",
            "Epoch 22/25\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.2470 - accuracy: 0.8845\n",
            "Epoch 23/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2146 - accuracy: 0.9027\n",
            "Epoch 24/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.2045 - accuracy: 0.9148\n",
            "Epoch 25/25\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.1992 - accuracy: 0.9111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d0fb75190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0eVr1wlenGg"
      },
      "source": [
        "# reshape test embeddings of task b\n",
        "a = np.array(test_vectors)\n",
        "test_vec = np.vstack(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLssx51oWnki"
      },
      "source": [
        "# get predictions for task b\n",
        "y_pred = model.predict(test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH4-1XwNfJUC"
      },
      "source": [
        "y_test = pd.factorize(y_true)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcpCDyguWnkj"
      },
      "source": [
        "res=[]\n",
        "for prediction in y_pred:\n",
        "    if prediction[0]<0.5:\n",
        "        res.append(1)\n",
        "    else:\n",
        "        res.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T58PCtRNWnkj",
        "outputId": "ce41d372-22bf-4adf-a9f8-cffcc5ecba1b"
      },
      "source": [
        "# get f1 score for task b\n",
        "f1_score(y_test, res, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12402669632925473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlonmxXjWnkj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKxtqK9BWnkj"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(2480, input_dim=768, activation='relu'))\n",
        "model.add(Dense(1260, activation='relu'))\n",
        "model.add(Dense(640, activation='relu'))\n",
        "model.add(Dense(160, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVpKyrxWnkj"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmn3Nf68Wnkj",
        "outputId": "83ac2403-2221-4b75-b0dd-2d02da48cfb5"
      },
      "source": [
        "# train the model\n",
        "model.fit(train_vec, y, epochs=50, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "69/69 [==============================] - 6s 65ms/step - loss: 0.5445 - accuracy: 0.8290\n",
            "Epoch 2/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3649 - accuracy: 0.8817\n",
            "Epoch 3/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3585 - accuracy: 0.8828\n",
            "Epoch 4/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3463 - accuracy: 0.8879\n",
            "Epoch 5/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3532 - accuracy: 0.8815\n",
            "Epoch 6/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3404 - accuracy: 0.8881\n",
            "Epoch 7/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3513 - accuracy: 0.8820\n",
            "Epoch 8/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3486 - accuracy: 0.8832\n",
            "Epoch 9/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3674 - accuracy: 0.8711\n",
            "Epoch 10/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3404 - accuracy: 0.8839\n",
            "Epoch 11/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3513 - accuracy: 0.8790\n",
            "Epoch 12/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3416 - accuracy: 0.8826\n",
            "Epoch 13/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3358 - accuracy: 0.8836\n",
            "Epoch 14/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3470 - accuracy: 0.8794\n",
            "Epoch 15/50\n",
            "69/69 [==============================] - 5s 66ms/step - loss: 0.3414 - accuracy: 0.8814\n",
            "Epoch 16/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3407 - accuracy: 0.8824\n",
            "Epoch 17/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3592 - accuracy: 0.8691\n",
            "Epoch 18/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3433 - accuracy: 0.8752\n",
            "Epoch 19/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3357 - accuracy: 0.8831\n",
            "Epoch 20/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3408 - accuracy: 0.8780\n",
            "Epoch 21/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3332 - accuracy: 0.8826\n",
            "Epoch 22/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3220 - accuracy: 0.8845\n",
            "Epoch 23/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3188 - accuracy: 0.8865\n",
            "Epoch 24/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3410 - accuracy: 0.8796\n",
            "Epoch 25/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3297 - accuracy: 0.8828\n",
            "Epoch 26/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3391 - accuracy: 0.8784\n",
            "Epoch 27/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3329 - accuracy: 0.8821\n",
            "Epoch 28/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3300 - accuracy: 0.8800\n",
            "Epoch 29/50\n",
            "69/69 [==============================] - 5s 66ms/step - loss: 0.3190 - accuracy: 0.8900\n",
            "Epoch 30/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3306 - accuracy: 0.8823\n",
            "Epoch 31/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3360 - accuracy: 0.8792\n",
            "Epoch 32/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3209 - accuracy: 0.8858\n",
            "Epoch 33/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3388 - accuracy: 0.8781\n",
            "Epoch 34/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3178 - accuracy: 0.8856\n",
            "Epoch 35/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3175 - accuracy: 0.8868\n",
            "Epoch 36/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3297 - accuracy: 0.8781\n",
            "Epoch 37/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3236 - accuracy: 0.8838\n",
            "Epoch 38/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3267 - accuracy: 0.8806\n",
            "Epoch 39/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3223 - accuracy: 0.8871\n",
            "Epoch 40/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3195 - accuracy: 0.8845\n",
            "Epoch 41/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3231 - accuracy: 0.8860\n",
            "Epoch 42/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3275 - accuracy: 0.8792\n",
            "Epoch 43/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3301 - accuracy: 0.8777\n",
            "Epoch 44/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3272 - accuracy: 0.8768\n",
            "Epoch 45/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3114 - accuracy: 0.8835\n",
            "Epoch 46/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3186 - accuracy: 0.8787\n",
            "Epoch 47/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3302 - accuracy: 0.8747\n",
            "Epoch 48/50\n",
            "69/69 [==============================] - 4s 65ms/step - loss: 0.3253 - accuracy: 0.8800\n",
            "Epoch 49/50\n",
            "69/69 [==============================] - 4s 63ms/step - loss: 0.3319 - accuracy: 0.8736\n",
            "Epoch 50/50\n",
            "69/69 [==============================] - 4s 64ms/step - loss: 0.3213 - accuracy: 0.8824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d0b1c7450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCkQuykUWnkj"
      },
      "source": [
        "# get predictions for subtask b\n",
        "y_pred = model.predict(test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o2bX3M1Wnkj"
      },
      "source": [
        "res=[]\n",
        "for prediction in y_pred:\n",
        "    if prediction[0]<0.5:\n",
        "        res.append(1)\n",
        "    else:\n",
        "        res.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWOUu9VeWnkj",
        "outputId": "3f8c3f13-a4da-4c5a-b2f6-e232c2af4e87"
      },
      "source": [
        "# get f1 score of subtask b\n",
        "f1_score(y_test, res, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47019867549668876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEnIegdSW9nT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDm4RUHyoNia"
      },
      "source": [
        "TASK C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OROl1BgWW9qk"
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv('/content/drive/MyDrive/OLIDv1.0/olid-training-v1.0.tsv', sep='\\t')\n",
        "data = data[data['subtask_c'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTOdAjsXW-aH"
      },
      "source": [
        "# call to the preprocessing function.\n",
        "data_pre = t_preprocess(data['tweet'].tolist())\n",
        "data_pre_test = t_preprocess(data_test_c['tweet'].tolist())\n",
        "y_true = label_test_c[1].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TwKLpBrW-aH"
      },
      "source": [
        "# get the vectors for the tweets in the train and test data using count vectorizer.\n",
        "# here processed tweets are used.\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "vectorizer.fit(data_pre)\n",
        "\n",
        "train_vectors = vectorizer.transform(data_pre)\n",
        "test_vectors = vectorizer.transform(data_pre_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS6_9JNAW-aH",
        "outputId": "221935af-e554-4e30-ad87-c123f231bac4"
      },
      "source": [
        "# training logistic regression model for subtask c on count vectorizer\n",
        "model = LogisticRegression()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Jrp7wWW-aH"
      },
      "source": [
        "# testing Logistic regression model on test data of subtask c on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btp3h0olW-aH",
        "outputId": "0a80c3c7-2b5a-4839-beac-aee799f85c80"
      },
      "source": [
        "# get f1-score for subtask c for logistic regression model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4940509657517045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46aBxAR_W-aI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIlu5v0PW-aI",
        "outputId": "8f4ef08d-5487-4f4f-f3ff-9692b82ae14a"
      },
      "source": [
        "# training naive bayes model for subtask c on count vectorizer\n",
        "model = naive_bayes.MultinomialNB()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrrNiXWeW-aI"
      },
      "source": [
        "# testing naive bayes model on test data of subtask c on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEK7c8a6W-aI",
        "outputId": "3f6da66a-1755-443e-b738-9b7c6ac5906a"
      },
      "source": [
        "# get f1-score for subtask c for naive bayes model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4072622240561172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLdyWsm1W-aI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9IHhHp3W-aI",
        "outputId": "2880ac67-2c55-4599-e8e1-54dc7ab90c46"
      },
      "source": [
        "# training Random Forest model for subtask c on count vectorizer\n",
        "model = RandomForestClassifier()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2u9B6FYW-aI"
      },
      "source": [
        "# testing Random Forest model on test data of subtask c on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cocK2tHzW-aI",
        "outputId": "6cf1eb38-3bac-4978-d5ca-7ef908ded7f3"
      },
      "source": [
        "# get f1-score for subtask c for Random Forest model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4783515323275263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jN9N10pW-aI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Donay351W-aI",
        "outputId": "2f15818c-49f0-46a2-a9d9-32bee8f77ed7"
      },
      "source": [
        "# training XGBoost model for subtask c on count vectorizer\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPHj3uQ1W-aI"
      },
      "source": [
        "# testing XGBoost model on test data of subtask c on count vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-i7HKpNW-aI",
        "outputId": "c09ad896-a330-46eb-c026-a260b27489e7"
      },
      "source": [
        "# get f1-score for subtask a for XGBoost model on count vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4549436212841302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8h3oWnxW-aI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZdL8NcwW-aI"
      },
      "source": [
        "# get the vectors for the tweets in the train and test data using tfidf vectorizer.\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "vectorizer.fit(data_pre)\n",
        "\n",
        "train_vectors = vectorizer.transform(data_pre)\n",
        "test_vectors = vectorizer.transform(data_pre_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7NkWJSiW-aI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLSoyPfqW-aI",
        "outputId": "00e07af3-d1d1-478c-c422-351d71834fc5"
      },
      "source": [
        "# training logistic regression model for subtask c on tfidf vectorizer\n",
        "model = LogisticRegression()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ZEdIDDW-aI"
      },
      "source": [
        "# testing Logistic regression model on test data of subtask c on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj842t22W-aI",
        "outputId": "3ecb10a4-3cdf-4b81-a94d-24a3333e4cad"
      },
      "source": [
        "# get f1-score for subtask c for logistic regression model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43885775825803086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkweSdNsW-aI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akm5tvHgW-aI",
        "outputId": "8bfe9909-ea57-4c95-e397-169fcd74c335"
      },
      "source": [
        "# training naive bayes model for subtask c on tfidf vectorizer\n",
        "model = naive_bayes.MultinomialNB()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_uASEb9W-aJ"
      },
      "source": [
        "# testing naive bayes model on test data of subtask c on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPpKOlcRW-aJ",
        "outputId": "608788a6-299d-4ae6-bcd2-347ca11dae41"
      },
      "source": [
        "# get f1-score for subtask c for naive bayes model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21436227224008575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrjfnJvJW-aJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKFAsqAcW-aJ",
        "outputId": "e089375e-eb0d-4a3b-bcfd-fb91c14313a4"
      },
      "source": [
        "# training Random Forest model for subtask c on tfidf vectorizer\n",
        "model = RandomForestClassifier()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V6VPnm7W-aJ"
      },
      "source": [
        "# testing Random Forest model on test data of subtask c on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVJTVmJuW-aJ",
        "outputId": "b8635583-6258-4563-9907-f9692823c75d"
      },
      "source": [
        "# get f1-score for subtask c for Random Forest model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4841138659320477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va7ozVu6W-aJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVUH4tQ4W-aJ",
        "outputId": "9885e044-9051-4db6-cf30-01d42ede58c4"
      },
      "source": [
        "# training XGBoost model for subtask c on tfidf vectorizer\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(train_vectors, data['subtask_c'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsu2SBWuW-aJ"
      },
      "source": [
        "# testing XGBoost model on test data of subtask c on tfidf vectorizer\n",
        "y_pred = model.predict(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOzvkbwW-aJ",
        "outputId": "f6cb2404-e2c1-4886-9785-015a907aecc3"
      },
      "source": [
        "# get f1-score for subtask c for XGBoost model on tfidf vectorizer\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45999439304737866"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G31fUeQiW-aJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyTN9NMEW-aJ"
      },
      "source": [
        "# get word embeddings of the tweets using distil bert for training set\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "feat_train = []\n",
        "for i in tqdm(range(len(data_pre))):\n",
        "    inputs = tokenizer(data_pre[i], return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    feat.append(outputs)\n",
        "\n",
        "np.save('distilbert_features.npy', feat_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHum5pkxW-aJ"
      },
      "source": [
        "# get word embeddings of the tweets using distil bert for test set\n",
        "feat_test = []\n",
        "for i in tqdm(range(len(data_pre_test))):\n",
        "    inputs = tokenizer(data_pre_test[i], return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    feat.append(outputs)\n",
        "\n",
        "np.save('distilbert_testc_features.npy', feat_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugTSZi5YW-aJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVa63PggW-aJ"
      },
      "source": [
        "feat = np.load(\"/content/drive/MyDrive/OLIDv1.0/distilbert_features.npy\",allow_pickle=True)\n",
        "feat_test = np.load(\"/content/drive/MyDrive/OLIDv1.0/distilbert_testc_features.npy\",allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FhdgAJVW-aJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX4kSzN6hIJM"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/OLIDv1.0/olid-training-v1.0.tsv', sep='\\t')\n",
        "data['bert'] = feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FcftGE0hIJN"
      },
      "source": [
        "# remove null values\n",
        "data = data[data['subtask_c'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7394Ocg3hPVB"
      },
      "source": [
        "feat = data['bert'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOMm-FcnW-aJ"
      },
      "source": [
        "train_vectors = []\n",
        "for i in range(len(feat)):\n",
        "  train_vectors.append(feat[i][0][0][0].detach().numpy())\n",
        "\n",
        "test_vectors = []\n",
        "for i in range(len(feat_test)):\n",
        "  test_vectors.append(feat_test[i][0][0][0].detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqMTgh0TW-aJ"
      },
      "source": [
        "y = pd.factorize(data['subtask_c'])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPsGJMcvW-aJ"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(2480, input_dim=768, activation='relu'))\n",
        "model.add(Dense(1260, activation='relu'))\n",
        "model.add(Dense(640, activation='relu'))\n",
        "model.add(Dense(320, activation='relu'))\n",
        "model.add(Dense(160, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFcAkeWLW-aJ"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mttiL8HGW-aJ"
      },
      "source": [
        "# reshape word embeddings of training set\n",
        "a = np.array(train_vectors)\n",
        "train_vec = np.vstack(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAY5P6b1W-aJ",
        "outputId": "c0eb5b78-b641-47bd-86b3-2a159aa0b711"
      },
      "source": [
        "# train model\n",
        "model.fit(train_vec, y, epochs=50, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "61/61 [==============================] - 6s 72ms/step - loss: 1.0224 - accuracy: 0.2616\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.9095 - accuracy: 0.5393\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.8009 - accuracy: 0.6244\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.8114 - accuracy: 0.6188\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.7498 - accuracy: 0.6245\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.7532 - accuracy: 0.6799\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.7369 - accuracy: 0.6947\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.7286 - accuracy: 0.6876\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.7387 - accuracy: 0.6850\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.7122 - accuracy: 0.7051\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.6935 - accuracy: 0.7146\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.7002 - accuracy: 0.7196\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 5s 74ms/step - loss: 0.6828 - accuracy: 0.7134\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.6724 - accuracy: 0.7209\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.6611 - accuracy: 0.7319\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.6629 - accuracy: 0.7350\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.6583 - accuracy: 0.7309\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.6198 - accuracy: 0.7586\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.6499 - accuracy: 0.7297\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.6131 - accuracy: 0.7566\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.5786 - accuracy: 0.7619\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.5704 - accuracy: 0.7660\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.5741 - accuracy: 0.7713\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.5863 - accuracy: 0.7597\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.5255 - accuracy: 0.7908\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.5065 - accuracy: 0.8014\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.5218 - accuracy: 0.7882\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.5223 - accuracy: 0.7919\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.4996 - accuracy: 0.8003\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.4319 - accuracy: 0.8376\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.4056 - accuracy: 0.8292\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.3965 - accuracy: 0.8405\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.3937 - accuracy: 0.8452\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.3802 - accuracy: 0.8466\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.3932 - accuracy: 0.8473\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.3457 - accuracy: 0.8636\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.3288 - accuracy: 0.8728\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.2898 - accuracy: 0.8854\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.2928 - accuracy: 0.8835\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.2497 - accuracy: 0.8934\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.2697 - accuracy: 0.8945\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.2549 - accuracy: 0.8988\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.2230 - accuracy: 0.9127\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.2223 - accuracy: 0.9098\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.2107 - accuracy: 0.9153\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.2101 - accuracy: 0.9106\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.2011 - accuracy: 0.9217\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.1695 - accuracy: 0.9295\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.1916 - accuracy: 0.9264\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.1579 - accuracy: 0.9360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d14bd9e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bU1iJ4hiF0y"
      },
      "source": [
        "# reshape test embeddings\n",
        "a = np.array(test_vectors)\n",
        "test_vec = np.vstack(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-waLuZkW-aJ"
      },
      "source": [
        "# predict labels for task c\n",
        "y_pred = model.predict(test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G85FjXxhi7Wq"
      },
      "source": [
        "y_test = pd.factorize(y_true)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjUae2idW-aJ"
      },
      "source": [
        "res=[]\n",
        "for prediction in y_pred:\n",
        "  max_value = prediction.argmax(axis=0)\n",
        "  res.append(max_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfDttb7uW-aJ",
        "outputId": "fbb1b850-7f5d-4340-bffa-26a6cd7975c9"
      },
      "source": [
        "# get f1 score\n",
        "f1_score(y_test, res, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2514942974378857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_qNTVoPW-aK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CugLu1mOW-aK"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(2480, input_dim=768, activation='relu'))\n",
        "model.add(Dense(1260, activation='relu'))\n",
        "model.add(Dense(640, activation='relu'))\n",
        "model.add(Dense(160, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(3, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nHqHM9uW-aK"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsQhs5ncW-aK",
        "outputId": "7fdcf110-825d-4b1c-d86d-8961c707fae7"
      },
      "source": [
        "# train the model\n",
        "model.fit(train_vec, y, epochs=30, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "61/61 [==============================] - 5s 65ms/step - loss: 0.9285 - accuracy: 0.6071\n",
            "Epoch 2/30\n",
            "61/61 [==============================] - 4s 62ms/step - loss: 0.8296 - accuracy: 0.6327\n",
            "Epoch 3/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.8193 - accuracy: 0.6532\n",
            "Epoch 4/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.8070 - accuracy: 0.6515\n",
            "Epoch 5/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7789 - accuracy: 0.6783\n",
            "Epoch 6/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7724 - accuracy: 0.6759\n",
            "Epoch 7/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7839 - accuracy: 0.6683\n",
            "Epoch 8/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7800 - accuracy: 0.6636\n",
            "Epoch 9/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7867 - accuracy: 0.6653\n",
            "Epoch 10/30\n",
            "61/61 [==============================] - 4s 62ms/step - loss: 0.7710 - accuracy: 0.6735\n",
            "Epoch 11/30\n",
            "61/61 [==============================] - 4s 64ms/step - loss: 0.7399 - accuracy: 0.6939\n",
            "Epoch 12/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7821 - accuracy: 0.6664\n",
            "Epoch 13/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7653 - accuracy: 0.6703\n",
            "Epoch 14/30\n",
            "61/61 [==============================] - 4s 64ms/step - loss: 0.7528 - accuracy: 0.6835\n",
            "Epoch 15/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7463 - accuracy: 0.6886\n",
            "Epoch 16/30\n",
            "61/61 [==============================] - 4s 65ms/step - loss: 0.7362 - accuracy: 0.6934\n",
            "Epoch 17/30\n",
            "61/61 [==============================] - 4s 64ms/step - loss: 0.7568 - accuracy: 0.6889\n",
            "Epoch 18/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7446 - accuracy: 0.6811\n",
            "Epoch 19/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7307 - accuracy: 0.7021\n",
            "Epoch 20/30\n",
            "61/61 [==============================] - 4s 62ms/step - loss: 0.7132 - accuracy: 0.7025\n",
            "Epoch 21/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7309 - accuracy: 0.6970\n",
            "Epoch 22/30\n",
            "61/61 [==============================] - 4s 64ms/step - loss: 0.7229 - accuracy: 0.6988\n",
            "Epoch 23/30\n",
            "61/61 [==============================] - 4s 62ms/step - loss: 0.7154 - accuracy: 0.7066\n",
            "Epoch 24/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7052 - accuracy: 0.7108\n",
            "Epoch 25/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7274 - accuracy: 0.7006\n",
            "Epoch 26/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7310 - accuracy: 0.6948\n",
            "Epoch 27/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7135 - accuracy: 0.7010\n",
            "Epoch 28/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7228 - accuracy: 0.7035\n",
            "Epoch 29/30\n",
            "61/61 [==============================] - 4s 63ms/step - loss: 0.7283 - accuracy: 0.6935\n",
            "Epoch 30/30\n",
            "61/61 [==============================] - 4s 64ms/step - loss: 0.7041 - accuracy: 0.7073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d0b6e4d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGg-iQrRW-aK"
      },
      "source": [
        "# get predictions for task c\n",
        "y_pred = model.predict(test_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gehiHLpBW-aK"
      },
      "source": [
        "res=[]\n",
        "for prediction in y_pred:\n",
        "  max_value = prediction.argmax(axis=0)\n",
        "  res.append(max_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZtpSxLFW-aK",
        "outputId": "d3f12942-8052-4db7-c3a0-721587ca76b7"
      },
      "source": [
        "# get f1 score for task c\n",
        "f1_score(y_test, res, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15476190476190477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 335
        }
      ]
    }
  ]
}